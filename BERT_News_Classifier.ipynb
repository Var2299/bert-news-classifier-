{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a0681",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q torch transformers pandas scikit-learn tqdm matplotlib seaborn\n",
    "\n",
    "import os, torch, pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Load dataset\n",
    "categories = ['sci.med', 'sci.space']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test  = fetch_20newsgroups(subset='test',  categories=categories)\n",
    "\n",
    "train_df = pd.DataFrame({'text': train.data, 'label': train.target}).sample(200, random_state=42)\n",
    "test_df  = pd.DataFrame({'text': test.data,  'label': test.target}).sample(50,  random_state=42)\n",
    "\n",
    "# 2. Initialize tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model     = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "\n",
    "# 3. Tokenize\n",
    "def tokenize(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "train_enc = tokenize(train_df['text'].tolist())\n",
    "test_enc  = tokenize(test_df['text'].tolist())\n",
    "\n",
    "# 4. Dataset\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = NewsDataset(train_enc, train_df['label'].values)\n",
    "test_dataset  = NewsDataset(test_enc,  test_df['label'].values)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "# 5. Train with loss tracking\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "train_losses = []\n",
    "model.train()\n",
    "for batch in tqdm(train_loader, desc=\"üì¶ Training\"):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "# 6. Evaluate\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"üìä Evaluating\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        preds = outputs.logits.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "accuracy = (torch.tensor(all_preds) == torch.tensor(all_labels)).float().mean().item()\n",
    "print(f\"\\n‚úÖ Test Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# 7. Classification Report\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Medical\", \"Science\"]))\n",
    "\n",
    "# 8. Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Medical\", \"Science\"], yticklabels=[\"Medical\", \"Science\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"conf_matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "# 9. Loss Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.title(\"Training Loss Over Batches\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_loss.png\")\n",
    "plt.show()\n",
    "\n",
    "# 10. Sample Predictions\n",
    "samples = [\n",
    "    \"This new study on protein folding is groundbreaking in medicine.\",\n",
    "    \"NASA's telescope revealed more about distant galaxies.\",\n",
    "    \"A breakthrough in cancer treatment was announced yesterday.\",\n",
    "    \"The astronauts are preparing for their mission to Mars.\",\n",
    "]\n",
    "\n",
    "print(\"\\nüîç Sample Predictions:\")\n",
    "model.eval()\n",
    "for i, text in enumerate(samples):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        pred = logits.argmax(dim=1).item()\n",
    "    print(f\"Sample {i+1}: \\\"{text[:60]}...\\\" ‚Üí Prediction: {'Science' if pred == 1 else 'Medical'}\")\n",
    "\n",
    "# 11. Save model\n",
    "torch.save(model.state_dict(), \"bert_science_medical.pth\")\n",
    "print(\"\\nüíæ Model saved as 'bert_science_medical.pth'\")\n",
    "\n",
    "# 12. Show trainable parameter count\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"üß† Total Trainable Parameters: {total_params:,}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
